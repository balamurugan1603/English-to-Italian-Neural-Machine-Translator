{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05423826",
   "metadata": {
    "papermill": {
     "duration": 0.015489,
     "end_time": "2021-10-15T03:59:34.225058",
     "exception": false,
     "start_time": "2021-10-15T03:59:34.209569",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Converting to TFLite :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a974055",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-10-15T03:59:34.266907Z",
     "iopub.status.busy": "2021-10-15T03:59:34.266009Z",
     "iopub.status.idle": "2021-10-15T03:59:39.126127Z",
     "shell.execute_reply": "2021-10-15T03:59:39.125065Z",
     "shell.execute_reply.started": "2021-10-14T06:02:43.940427Z"
    },
    "papermill": {
     "duration": 4.886435,
     "end_time": "2021-10-15T03:59:39.126325",
     "exception": false,
     "start_time": "2021-10-15T03:59:34.239890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 03:59:34.888132: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2021-10-15 03:59:34.888240: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Importing dependancies\n",
    "from tensorflow import lite\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f2be09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T03:59:39.162233Z",
     "iopub.status.busy": "2021-10-15T03:59:39.161595Z",
     "iopub.status.idle": "2021-10-15T03:59:54.003667Z",
     "shell.execute_reply": "2021-10-15T03:59:54.004198Z",
     "shell.execute_reply.started": "2021-10-14T06:02:49.164286Z"
    },
    "papermill": {
     "duration": 14.863002,
     "end_time": "2021-10-15T03:59:54.004407",
     "exception": false,
     "start_time": "2021-10-15T03:59:39.141405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 03:59:39.323925: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-15 03:59:39.326403: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2021-10-15 03:59:39.326445: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-10-15 03:59:39.326471: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (91b52915cfa0): /proc/driver/nvidia/version does not exist\n",
      "2021-10-15 03:59:39.326727: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-15 03:59:39.327062: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "# Initialising converters\n",
    "encoder_tflite_converter = lite.TFLiteConverter.from_saved_model(\"../input/neural-machine-translation-english-to-italian/encoder\")\n",
    "decoder_tflite_converter = lite.TFLiteConverter.from_saved_model(\"../input/neural-machine-translation-english-to-italian/decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a88a06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T03:59:54.039694Z",
     "iopub.status.busy": "2021-10-15T03:59:54.038618Z",
     "iopub.status.idle": "2021-10-15T03:59:54.040631Z",
     "shell.execute_reply": "2021-10-15T03:59:54.041158Z",
     "shell.execute_reply.started": "2021-10-14T06:03:07.603781Z"
    },
    "papermill": {
     "duration": 0.021973,
     "end_time": "2021-10-15T03:59:54.041348",
     "exception": false,
     "start_time": "2021-10-15T03:59:54.019375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining quantisation schema\n",
    "encoder_tflite_converter.optimizations = [lite.Optimize.DEFAULT]\n",
    "decoder_tflite_converter.optimizations = [lite.Optimize.DEFAULT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4a3fa0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T03:59:54.077573Z",
     "iopub.status.busy": "2021-10-15T03:59:54.076878Z",
     "iopub.status.idle": "2021-10-15T04:00:24.307816Z",
     "shell.execute_reply": "2021-10-15T04:00:24.307233Z",
     "shell.execute_reply.started": "2021-10-14T06:03:07.612411Z"
    },
    "papermill": {
     "duration": 30.25112,
     "end_time": "2021-10-15T04:00:24.307963",
     "exception": false,
     "start_time": "2021-10-15T03:59:54.056843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 03:59:54.306700: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored output_format.\n",
      "2021-10-15 03:59:54.306789: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:319] Ignored drop_control_dependency.\n",
      "2021-10-15 03:59:54.306800: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:325] Ignored change_concat_input_ranges.\n",
      "2021-10-15 03:59:54.307977: I tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: ../input/neural-machine-translation-english-to-italian/encoder\n",
      "2021-10-15 03:59:54.328374: I tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }\n",
      "2021-10-15 03:59:54.328437: I tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: ../input/neural-machine-translation-english-to-italian/encoder\n",
      "2021-10-15 03:59:54.328551: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-15 03:59:54.380129: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
      "2021-10-15 03:59:54.398274: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\n",
      "2021-10-15 03:59:54.410889: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
      "2021-10-15 03:59:54.760324: I tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: ../input/neural-machine-translation-english-to-italian/encoder\n",
      "2021-10-15 03:59:54.812333: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 504358 microseconds.\n",
      "2021-10-15 03:59:54.978334: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:194] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2021-10-15 03:59:55.528458: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-15 04:00:02.095375: I tensorflow/lite/tools/optimize/quantize_weights.cc:231] Skipping quantization of tensor arg5 because it has no allocated buffer.\n",
      "2021-10-15 04:00:03.201677: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored output_format.\n",
      "2021-10-15 04:00:03.201746: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:319] Ignored drop_control_dependency.\n",
      "2021-10-15 04:00:03.201756: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:325] Ignored change_concat_input_ranges.\n",
      "2021-10-15 04:00:03.202033: I tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: ../input/neural-machine-translation-english-to-italian/decoder\n",
      "2021-10-15 04:00:03.215579: I tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }\n",
      "2021-10-15 04:00:03.215646: I tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: ../input/neural-machine-translation-english-to-italian/decoder\n",
      "2021-10-15 04:00:03.215712: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-15 04:00:03.260660: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\n",
      "2021-10-15 04:00:03.852291: I tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: ../input/neural-machine-translation-english-to-italian/decoder\n",
      "2021-10-15 04:00:03.899453: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 697420 microseconds.\n",
      "2021-10-15 04:00:22.383541: I tensorflow/lite/tools/optimize/quantize_weights.cc:231] Skipping quantization of tensor arg5 becaus"
     ]
    }
   ],
   "source": [
    "# Converting to TFLite\n",
    "encoder_tflite_content = encoder_tflite_converter.convert()\n",
    "decoder_tflite_content = decoder_tflite_converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba4ec644",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T04:00:24.344202Z",
     "iopub.status.busy": "2021-10-15T04:00:24.343579Z",
     "iopub.status.idle": "2021-10-15T04:00:24.604857Z",
     "shell.execute_reply": "2021-10-15T04:00:24.604339Z",
     "shell.execute_reply.started": "2021-10-14T06:03:37.859601Z"
    },
    "papermill": {
     "duration": 0.281428,
     "end_time": "2021-10-15T04:00:24.605013",
     "exception": false,
     "start_time": "2021-10-15T04:00:24.323585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e it has no allocated buffer.\n"
     ]
    }
   ],
   "source": [
    "# Saving quantised models\n",
    "with open(\"./encoder.tflite\", 'wb') as f:\n",
    "    f.write(encoder_tflite_content)\n",
    "\n",
    "with open(\"./decoder.tflite\", 'wb') as f:\n",
    "    f.write(decoder_tflite_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208496e0",
   "metadata": {
    "papermill": {
     "duration": 0.015641,
     "end_time": "2021-10-15T04:00:24.636754",
     "exception": false,
     "start_time": "2021-10-15T04:00:24.621113",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Inference from quantised model :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "403dcbd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T04:00:24.673588Z",
     "iopub.status.busy": "2021-10-15T04:00:24.672848Z",
     "iopub.status.idle": "2021-10-15T04:00:24.674791Z",
     "shell.execute_reply": "2021-10-15T04:00:24.675243Z",
     "shell.execute_reply.started": "2021-10-14T06:03:38.124848Z"
    },
    "papermill": {
     "duration": 0.022756,
     "end_time": "2021-10-15T04:00:24.675428",
     "exception": false,
     "start_time": "2021-10-15T04:00:24.652672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing Dependancies\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5337fe64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T04:00:24.712208Z",
     "iopub.status.busy": "2021-10-15T04:00:24.711586Z",
     "iopub.status.idle": "2021-10-15T04:00:24.802354Z",
     "shell.execute_reply": "2021-10-15T04:00:24.802887Z",
     "shell.execute_reply.started": "2021-10-14T06:03:38.131596Z"
    },
    "papermill": {
     "duration": 0.110272,
     "end_time": "2021-10-15T04:00:24.803059",
     "exception": false,
     "start_time": "2021-10-15T04:00:24.692787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading tokenizers\n",
    "eng_tok = pickle.load(open(\"../input/neural-machine-translation-english-to-italian/English Tokenizer.pkl\", 'rb'))\n",
    "it_tok = pickle.load(open(\"../input/neural-machine-translation-english-to-italian/Italian Tokenizer.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c269b30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T04:00:24.838973Z",
     "iopub.status.busy": "2021-10-15T04:00:24.838352Z",
     "iopub.status.idle": "2021-10-15T04:00:24.842233Z",
     "shell.execute_reply": "2021-10-15T04:00:24.842759Z",
     "shell.execute_reply.started": "2021-10-14T06:03:38.247589Z"
    },
    "papermill": {
     "duration": 0.023327,
     "end_time": "2021-10-15T04:00:24.842922",
     "exception": false,
     "start_time": "2021-10-15T04:00:24.819595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eng_seq_len = 20    # First dimension of encoder Input shape\n",
    "eng_vocab_size = len(eng_tok.word_index)+1    # Second dimension of encoder Input shape\n",
    "\n",
    "it_seq_len = 20     # First dimension of decoder Input shape\n",
    "it_vocab_size = len(it_tok.word_index)+1     # Second dimension of decoder Input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b481c28a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T04:00:24.886679Z",
     "iopub.status.busy": "2021-10-15T04:00:24.885979Z",
     "iopub.status.idle": "2021-10-15T04:00:24.887501Z",
     "shell.execute_reply": "2021-10-15T04:00:24.888001Z",
     "shell.execute_reply.started": "2021-10-14T06:03:38.254856Z"
    },
    "papermill": {
     "duration": 0.029326,
     "end_time": "2021-10-15T04:00:24.888159",
     "exception": false,
     "start_time": "2021-10-15T04:00:24.858833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sent_to_seq(sequences, tokenizer, vocab_size=None, reverse=False, onehot=False):\n",
    "    \n",
    "    \"\"\" Converts text data into sequences supported by model input layers.\n",
    "    \n",
    "    Args:\n",
    "        sequences (list): List of text data.\n",
    "        tokenizer (tf.keras.preprocessing.text.Tokenizer): Tensorflow tokenizer object.\n",
    "        vocab_size (int): Number of words in the whole vocabulary.\n",
    "        reverse (bool): Reverses the padded sequence if set True. Defaults False.\n",
    "                        (Eg: if set True, [1 2 3 0 0] becomes [0 0 3 2 1])\n",
    "        onehot (bool): Creates onehot representation of the padded sequence if set True.\n",
    "                       Defaults False.\n",
    "                       \n",
    "    Returns:\n",
    "        preprocessed_seq (list): List of preprocessed sequences.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Tokenizing\n",
    "    seq = tokenizer.texts_to_sequences(sequences)\n",
    "    \n",
    "    # Padding\n",
    "    preprocessed_seq = pad_sequences(seq, padding='post', truncating='post', maxlen=20)\n",
    "    \n",
    "    # Reversing\n",
    "    if reverse:\n",
    "        preprocessed_seq = preprocessed_seq[:, ::-1]\n",
    "    \n",
    "    # Onehot encoding\n",
    "    if onehot:\n",
    "        preprocessed_seq = to_categorical(preprocessed_seq, num_classes=vocab_size) \n",
    "    \n",
    "    return preprocessed_seq\n",
    "\n",
    "            \n",
    "\n",
    "def word_to_onehot(tokenizer, word, vocab_size):\n",
    "    \n",
    "    \"\"\" Converts a single word into onehot representation.\n",
    "    \n",
    "    Args:\n",
    "        tokenizer (tf.keras.preprocessing.text.Tokenizer): Tensorflow tokenizer object.\n",
    "        word (str): Word to be tokenized and onehot encoded.\n",
    "        vocab_size (int): Number of words in the whole vocabulary.\n",
    "    \n",
    "    Returns:\n",
    "        de_onhot (list): Onehot representation of given word.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    de_seq = tokenizer.texts_to_sequences([[word]])\n",
    "    de_onehot = to_categorical(de_seq, num_classes=vocab_size).reshape(1, 1, vocab_size)  \n",
    "    \n",
    "    return de_onehot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "745d56c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T04:00:24.923280Z",
     "iopub.status.busy": "2021-10-15T04:00:24.922653Z",
     "iopub.status.idle": "2021-10-15T04:00:24.950292Z",
     "shell.execute_reply": "2021-10-15T04:00:24.949667Z",
     "shell.execute_reply.started": "2021-10-14T06:03:38.284556Z"
    },
    "papermill": {
     "duration": 0.046305,
     "end_time": "2021-10-15T04:00:24.950433",
     "exception": false,
     "start_time": "2021-10-15T04:00:24.904128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading TFLite models\n",
    "enc_interpreter = lite.Interpreter(model_path=\"./encoder.tflite\")\n",
    "dec_interpreter = lite.Interpreter(model_path=\"./decoder.tflite\")\n",
    "\n",
    "# Allocates tensors\n",
    "enc_interpreter.allocate_tensors()\n",
    "dec_interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d203cb43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T04:00:24.990000Z",
     "iopub.status.busy": "2021-10-15T04:00:24.989185Z",
     "iopub.status.idle": "2021-10-15T04:00:24.992194Z",
     "shell.execute_reply": "2021-10-15T04:00:24.992691Z",
     "shell.execute_reply.started": "2021-10-14T06:03:38.636304Z"
    },
    "papermill": {
     "duration": 0.026626,
     "end_time": "2021-10-15T04:00:24.992866",
     "exception": false,
     "start_time": "2021-10-15T04:00:24.966240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_input_3:0', 'index': 0, 'shape': array([    1,    20, 13893], dtype=int32), 'shape_signature': array([   -1,    20, 13893], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "# Input layer details\n",
    "en_input_details = enc_interpreter.get_input_details()\n",
    "de_input_details = dec_interpreter.get_input_details()\n",
    "\n",
    "# Output layer details\n",
    "en_output_details = enc_interpreter.get_output_details()\n",
    "de_output_details = dec_interpreter.get_output_details()\n",
    "\n",
    "print(enc_interpreter.get_input_details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "423f093e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T04:00:25.031147Z",
     "iopub.status.busy": "2021-10-15T04:00:25.030511Z",
     "iopub.status.idle": "2021-10-15T04:00:25.033412Z",
     "shell.execute_reply": "2021-10-15T04:00:25.034049Z",
     "shell.execute_reply.started": "2021-10-14T06:03:38.638038Z"
    },
    "papermill": {
     "duration": 0.024924,
     "end_time": "2021-10-15T04:00:25.034217",
     "exception": false,
     "start_time": "2021-10-15T04:00:25.009293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'serving_default_input_4:0', 'index': 1, 'shape': array([    1,     1, 28445], dtype=int32), 'shape_signature': array([   -1,     1, 28445], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n"
     ]
    }
   ],
   "source": [
    "print(de_input_details[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a69bf4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T04:00:25.072191Z",
     "iopub.status.busy": "2021-10-15T04:00:25.071553Z",
     "iopub.status.idle": "2021-10-15T04:00:25.074577Z",
     "shell.execute_reply": "2021-10-15T04:00:25.075235Z",
     "shell.execute_reply.started": "2021-10-14T06:03:38.639705Z"
    },
    "papermill": {
     "duration": 0.025013,
     "end_time": "2021-10-15T04:00:25.075475",
     "exception": false,
     "start_time": "2021-10-15T04:00:25.050462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'StatefulPartitionedCall:1', 'index': 25, 'shape': array([   1, 2048], dtype=int32), 'shape_signature': array([  -1, 2048], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:0', 'index': 30, 'shape': array([    1, 28445], dtype=int32), 'shape_signature': array([   -1, 28445], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "print(de_output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8776da2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T04:00:25.119799Z",
     "iopub.status.busy": "2021-10-15T04:00:25.119106Z",
     "iopub.status.idle": "2021-10-15T04:00:25.122307Z",
     "shell.execute_reply": "2021-10-15T04:00:25.121800Z",
     "shell.execute_reply.started": "2021-10-14T06:03:38.642973Z"
    },
    "papermill": {
     "duration": 0.02934,
     "end_time": "2021-10-15T04:00:25.122455",
     "exception": false,
     "start_time": "2021-10-15T04:00:25.093115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate(eng_sentence):\n",
    "    \n",
    "    \"\"\" Returns Italian translation of given english sentence.\n",
    "    \n",
    "    Args:\n",
    "        eng_sentence (str): English text to be translated.\n",
    "        \n",
    "    Returns:\n",
    "        it_sent (str): Italian translated text.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    en_seq = sent_to_seq([eng_sentence], \n",
    "                         tokenizer=eng_tok, \n",
    "                         reverse=True, \n",
    "                         onehot=True, \n",
    "                         vocab_size=eng_vocab_size)\n",
    "    \n",
    "    enc_interpreter.set_tensor(en_input_details[0]['index'], en_seq)\n",
    "    enc_interpreter.invoke()\n",
    "    \n",
    "    en_st = enc_interpreter.get_tensor(en_output_details[0]['index'])\n",
    "    de_seq = word_to_onehot(it_tok, \"sos\", it_vocab_size)\n",
    "\n",
    "    it_sent = \"\"\n",
    "    for i in range(it_seq_len):\n",
    "        dec_interpreter.set_tensor(de_input_details[0]['index'], en_st)\n",
    "        dec_interpreter.set_tensor(de_input_details[1]['index'], de_seq)\n",
    "        dec_interpreter.invoke()\n",
    "        en_st = dec_interpreter.get_tensor(de_output_details[0]['index'])\n",
    "        de_prob = dec_interpreter.get_tensor(de_output_details[1]['index'])\n",
    "        index = np.argmax(de_prob[0, :], axis=-1)\n",
    "        de_w = it_tok.index_word[index]\n",
    "        de_seq = word_to_onehot(it_tok, de_w, it_vocab_size) \n",
    "        if de_w == 'eos': break\n",
    "        it_sent += de_w + ' '\n",
    "        \n",
    "    return it_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b4ede3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T04:00:25.161535Z",
     "iopub.status.busy": "2021-10-15T04:00:25.160878Z",
     "iopub.status.idle": "2021-10-15T04:00:25.696043Z",
     "shell.execute_reply": "2021-10-15T04:00:25.695504Z",
     "shell.execute_reply.started": "2021-10-14T06:03:38.644859Z"
    },
    "papermill": {
     "duration": 0.556671,
     "end_time": "2021-10-15T04:00:25.696182",
     "exception": false,
     "start_time": "2021-10-15T04:00:25.139511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posso parlarvi per un minuto \n"
     ]
    }
   ],
   "source": [
    "# Making translations\n",
    "print(translate(\"Can I talk to you for a minute?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 62.750217,
   "end_time": "2021-10-15T04:00:29.120126",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-15T03:59:26.369909",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
